{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データのダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.requestを使ったダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib.request.urlretrieve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLと保存パスを指定\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"test.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存しました\n"
     ]
    }
   ],
   "source": [
    "# ダウンロード\n",
    "urllib.request.urlretrieve(url, savename)\n",
    "print(\"保存しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib.request.urlopen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"test.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロード\n",
    "mem = urllib.request.urlopen(url).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存しました\n"
     ]
    }
   ],
   "source": [
    "# ファイルへ保存\n",
    "# wは書き込みモード、bはバイナリモードを意味している。\n",
    "with open(savename, mode=\"wb\") as f:\n",
    "    f.write(mem)\n",
    "    print(\"保存しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Webからデータを取得する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クライアントの接持続情報を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを取得する\n",
    "url = \"http://api.aoikujira.com/ip/ini\"\n",
    "res = urllib.request.urlopen(url)\n",
    "data = res.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ip]\n",
      "API_URI=http://api.aoikujira.com/ip/get.php\n",
      "REMOTE_ADDR=114.158.218.36\n",
      "REMOTE_HOST=p11036-ipngn9901marunouchi.tokyo.ocn.ne.jp\n",
      "REMOTE_PORT=48256\n",
      "HTTP_HOST=api.aoikujira.com\n",
      "HTTP_USER_AGENT=Python-urllib/3.7\n",
      "HTTP_ACCEPT_LANGUAGE=\n",
      "HTTP_ACCEPT_CHARSET=\n",
      "SERVER_PORT=80\n",
      "FORMAT=ini\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# バイナリを文字列に変換\n",
    "text = data.decode(\"utf-8\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任意のパラメータをつけてリクエストを送信する方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このAPIは、以下のURLに対して郵便番号を指定すると、その番号に対応した住所を返すものとなっている\n",
    "# このエントリーポイントに対して、以下のパラメータを指定することになっている\n",
    "# fmt -> データのフォーマットをjsonからxmlで指定\n",
    "# zn  -> 住所を知りたい郵便番号を指定\n",
    "API = \"http://api.aoikujira.com/zip/xml/get.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータをURLにエンコードする\n",
    "# URLエンコードのために、urllib.parseモジュールを利用する\n",
    "# [補足]郵便番号など簡単な場合はenncodeせずにURLに直接書き込めるが、パラメータに日本が含まれれる場合はエンコードが必須となる\n",
    "values = {\n",
    "    'fmt': 'xml',\n",
    "    'zn': '1500042'\n",
    "}\n",
    "params = urllib.parse.urlencode(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url= http://api.aoikujira.com/zip/xml/get.php?fmt=xml&zn=1500042\n"
     ]
    }
   ],
   "source": [
    "# リクエスト用のURLを生成\n",
    "# [書式] GETリクエストでパラメータを送信する\n",
    "# http://example.com?key1=v1&key2=v2&...\n",
    "url = API + \"?\" + params\n",
    "print(\"url=\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n",
      "<address result=\"1\">\n",
      "<header>\n",
      "  <result>1</result>\n",
      "  <api>api.aoikujira.com/zip</api>\n",
      "  <version>1.1</version>\n",
      "</header>\n",
      "<value>\n",
      "  <zip>1500042</zip>\n",
      "  <ken>東京都</ken>\n",
      "  <shi>渋谷区</shi>\n",
      "  <cho>宇田川町</cho>\n",
      "  <disp>東京都渋谷区宇田川町</disp>\n",
      "  <kenkana>トウキョウト</kenkana>\n",
      "  <shikana>シブヤク</shikana>\n",
      "  <chokana>ウダガワチョウ</chokana>\n",
      "</value>\n",
      "</address>\n"
     ]
    }
   ],
   "source": [
    "# ダウンロード\n",
    "data = urllib.request.urlopen(url).read()\n",
    "text = data.decode(\"utf-8\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 百人一首を検索するコマンドを自作してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import urllib.request as req\n",
    "import urllib.parse as parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コマンドライン引数を得るために、sysモジュールを取り込んでいる\n",
    "# コマンドライン引数は、sys.argvにリスト型で設定されている\n",
    "# sys.argv[0] -> スクリプトの名前\n",
    "# sys.argv[1]以降にコマンドライン引数が設定されている\n",
    "\"\"\"\n",
    "# コマンドライン引数を得る\n",
    "if len(sys.argv)<=1:\n",
    "    print(\"USAGE: hyakunin.py (keyword)\")\n",
    "    sys.exit()\n",
    "keyword = sys.argv[1]\n",
    "\"\"\"\n",
    "keyword = \"秋の田\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url= http://api.aoikujira.com/hyakunin/get.php?fmt=ini&key=%E7%A7%8B%E3%81%AE%E7%94%B0\n"
     ]
    }
   ],
   "source": [
    "# パラメータをURLエンコードする\n",
    "# 日本語のキーワードが与えられているため、URLエンコードが必須となる\n",
    "# 百人一首検索APIのエントリーポイントに対して、パラメータは以下のように与える\n",
    "# fmt -> 検索結果の形式を ini | xml | json で指定\n",
    "# key -> 検索キーワードを指定\n",
    "API = \"http://api.aoikujira.com/hyakunin/get.php\"\n",
    "query = {\n",
    "    \"fmt\": \"ini\",\n",
    "    \"key\": keyword\n",
    "}\n",
    "params = parse.urlencode(query)\n",
    "url = API + \"?\" + params\n",
    "print(\"url=\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[item1]\n",
      "kami=秋の田の かりほの庵の 苫をあらみ\n",
      "simo=我が衣手は 露にぬれつつ\n",
      "kami_kana=あきのたのかりほのいほのとまをあらみ\n",
      "simo_kana=わかころもてはつゆにぬれつつ\n",
      "sakusya=天智天皇\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ダウンロード\n",
    "with req.urlopen(url) as r:\n",
    "    b = r.read()\n",
    "    data = b.decode('utf-8')\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoupでスクレイピング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoupの基本的な使い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析したいHTML\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <h1>スクレイピングとは？</h1>\n",
    "    <p>Webページを解析すること。</p>\n",
    "    <p>任意の箇所を抽出すること</p>\n",
    "</body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを解析する\n",
    "# 第一引数にHTMLを指定\n",
    "# 第二引数に解析を行うパーサーの種類を指定\n",
    "# -> HTMLを解析するには、\"html.parser\"を指定\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = スクレイピングとは？\n",
      "p = Webページを解析すること。\n",
      "p = 任意の箇所を抽出すること\n"
     ]
    }
   ],
   "source": [
    "# 任意の部分を抽出する\n",
    "# <html><body><h1>を抽出するには -> soup.html.body.h1\n",
    "# <p>が複数あり、soup.html.body.pだと最初の<p>が抽出される\n",
    "# next_siblingを用いる -> 一回目のnext_siblingでは</p>直後の改行やスペースが得られるため、二回行う。\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "# 要素のテキストを表示する\n",
    "print(\"h1 = \" + h1.string)\n",
    "print(\"p = \" + p1.string)\n",
    "print(\"p = \" + p2.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いくらなんでも、ルートを最初から辿るのはめんどくさい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任意のidで要素を探す方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoupでは、ルートからひとつずつ要素を辿る以外に、find()メソッドを利用して、任意のid属性を指定して要素を見つけることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <h1 id=\"title\">スクレイピングとは？</h1>\n",
    "    <p id=\"body\">Webページから任意のデータを抽出すること</p>\n",
    "</body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを解析する\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title = スクレイピングとは？\n",
      "#body = Webページから任意のデータを抽出すること\n"
     ]
    }
   ],
   "source": [
    "# find()メソッドで取り出す\n",
    "title = soup.find(id=\"title\")\n",
    "body = soup.find(id=\"body\")\n",
    "\n",
    "# テキスト部分を表示\n",
    "print(\"#title = \" + title.string)\n",
    "print(\"#body = \" + body.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複数の要素を取得する - find_all()メソッド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "    <ul>\n",
    "    <li><a href=\"http://uta.pw\">uta</a></li>\n",
    "    <li><a href=\"http://oto.chu.jp\">oto</a></li>\n",
    "    </ul>\n",
    "</body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを解析する\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all()メソッドで取り出す\n",
    "# 全ての\"a\"タグを抽出する\n",
    "links = soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uta > http://uta.pw\n",
      "oto > http://oto.chu.jp\n"
     ]
    }
   ],
   "source": [
    "# リンク一覧を表示\n",
    "# リンクのhref属性はattrs['href']のようにattrsプロパティにて\n",
    "# 説明テキストはstringプロパティにて取得できる\n",
    "for a in links:\n",
    "    href = a.attrs['href']\n",
    "    text = a.string\n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOM要素の属性について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOM: Document Object Model とは、XMLやHTMLの各要素にアクセスする仕組みのこと  \n",
    "DOM要素の属性とは、タグ名の後にある各属性のこと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(\n",
    "    \"<p><a href='a.html'>test</a></p>\",\n",
    "    \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>\\n <a href=\"a.html\">\\n  test\\n </a>\\n</p>'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 解析が正しくできているかを確認\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <a>タグを変数aに代入\n",
    "a = soup.p.a\n",
    "\n",
    "# attrsプロパティの方を確認\n",
    "type(a.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# href属性があるか確認\n",
    "'href' in a.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a.html'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# href属性の値を確認\n",
    "a['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urlopen() と BeautifulSoup の組み合わせ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://api.aoikujira.com/zip/xml/1500042\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urlopen()でデータを取得\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoupで解析\n",
    "soup = BeautifulSoup(res, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京都 渋谷区 宇田川町\n"
     ]
    }
   ],
   "source": [
    "# 任意のデータを抽出\n",
    "ken = soup.find(\"ken\").string\n",
    "shi = soup.find(\"shi\").string\n",
    "cho = soup.find(\"cho\").string\n",
    "print(ken, shi, cho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS セレクタを使う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoupでは、JavaScriptのライブラリjQueryのように、CSSのセレクタを指定して、任意の要素を抽出することもできる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|メソッド|解説|\n",
    "|-|-|\n",
    "|soup.select_one(セレクタ)|CSSセレクタで要素の一つを取り出す|\n",
    "|soup.select(セレクタ)|CSSセレクタで複数要素を取り出しリスト型で返す|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析対象となるHTML\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "    <h1>トルストイの名言</h1>\n",
    "    <ul class=\"items\">\n",
    "        <li>汝の心に教えよ、心に学ぶな</li>\n",
    "        <li>謙虚な人は誰からも好かれる。</li>\n",
    "        <li>強い人々は、いつも気取らない。</li>\n",
    "    </ul>\n",
    "</div>\n",
    "</html></body>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを解析する\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = トルストイの名言\n",
      "li = 汝の心に教えよ、心に学ぶな\n",
      "li = 謙虚な人は誰からも好かれる。\n",
      "li = 強い人々は、いつも気取らない。\n"
     ]
    }
   ],
   "source": [
    "# 必要な部分をCSSクエリで取り出す\n",
    "# タイトル部分を取得\n",
    "# select_one()メソッドを使って、<h1>タグを取り出す\n",
    "# 実際のWebサイトには複数個の<h1>タグが存在する場合があるため、CSSセレクタで詳細な構造を指定する\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print(\"h1 =\", h1)\n",
    "\n",
    "# リスト部分を取得\n",
    "# select()メソッドを使って、複数個の<li>タグを取り出す\n",
    "# ここでも、詳細な構造を指定することで、明確にリスト部分を取得している\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\")\n",
    "for li in li_list:\n",
    "    print(\"li =\", li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo! ファイナンスの為替情報を取得してみよう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを取得\n",
    "url = \"http://stocks.finance.yahoo.co.jp/stocks/detail/?code=usdjpy\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTMLを解析\n",
    "soup = BeautifulSoup(res, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd/jpy= 107.730000\n"
     ]
    }
   ],
   "source": [
    "# 任意のデータを抽出\n",
    "price = soup.select_one(\".stoksPrice\").string\n",
    "print(\"usd/jpy=\", price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nurl = \"http://api.aoikujira.com/kawase/xml/usd\"\\nres = req.urlopen(url)\\n\\n# HTMLを解析\\nsoup = BeautifulSoup(res, \"html.parser\")\\n\\n# 任意のデータを抽出\\njpy = soup.select_one(\"jpy\").string\\nprint(\"usd/jpy\", jpy)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 別のサイトからもやってみる -> Not Find 404\n",
    "\"\"\"\n",
    "url = \"http://api.aoikujira.com/kawase/xml/usd\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTMLを解析\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 任意のデータを抽出\n",
    "jpy = soup.select_one(\"jpy\").string\n",
    "print(\"usd/jpy\", jpy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 青空文庫で公開せれている夏目漱石の作品一覧を得る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "イズムの功過 > ../cards/000148/card2314.html\n",
      "一夜 > ../cards/000148/card1086.html\n",
      "永日小品 > ../cards/000148/card758.html\n",
      "岡本一平著並画『探訪画趣』序 > ../cards/000148/card2669.html\n",
      "おはなし > ../cards/000148/card59017.html\n",
      "思い出す事など > ../cards/000148/card792.html\n",
      "カーライル博物館 > ../cards/000148/card1046.html\n",
      "薤露行 > ../cards/000148/card769.html\n",
      "学者と名誉 > ../cards/000148/card2383.html\n",
      "硝子戸の中 > ../cards/000148/card760.html\n",
      "元日 > ../cards/000148/card2674.html\n",
      "鬼哭寺の一夜 > ../cards/000148/card58276.html\n",
      "木下杢太郎『唐草表紙』序 > ../cards/000148/card2670.html\n",
      "教育と文芸 > ../cards/000148/card778.html\n",
      "京に着ける夕 > ../cards/000148/card777.html\n",
      "京に着ける夕 > ../cards/000148/card55936.html\n",
      "虚子君へ > ../cards/000148/card2373.html\n",
      "草枕 > ../cards/000148/card776.html\n",
      "虞美人草 > ../cards/000148/card761.html\n",
      "ケーベル先生 > ../cards/000148/card770.html\n",
      "ケーベル先生の告別 > ../cards/000148/card771.html\n",
      "現代日本の開化 > ../cards/000148/card759.html\n",
      "行人 > ../cards/000148/card775.html\n",
      "坑夫 > ../cards/000148/card774.html\n",
      "こころ > ../cards/000148/card773.html\n",
      "『心』広告文 > ../cards/000148/card4689.html\n",
      "『心』自序 > ../cards/000148/card4688.html\n",
      "『心』予告 > ../cards/000148/card4687.html\n",
      "琴のそら音 > ../cards/000148/card1073.html\n",
      "コンラッドの描きたる自然について > ../cards/000148/card766.html\n",
      "作物の批評 > ../cards/000148/card793.html\n",
      "三山居士 > ../cards/000148/card784.html\n",
      "三四郎 > ../cards/000148/card794.html\n",
      "『三四郎』予告 > ../cards/000148/card4682.html\n",
      "子規の画 > ../cards/000148/card1749.html\n",
      "子規の画 > ../cards/000148/card795.html\n",
      "「自然を写す文章」 > ../cards/000148/card42297.html\n",
      "自転車日記 > ../cards/000148/card768.html\n",
      "写生文 > ../cards/000148/card796.html\n",
      "従軍行 > ../cards/000148/card58277.html\n",
      "趣味の遺伝 > ../cards/000148/card1104.html\n",
      "初秋の一日 > ../cards/000148/card797.html\n",
      "処女作追懐談 > ../cards/000148/card2680.html\n",
      "人生 > ../cards/000148/card767.html\n",
      "鈴木三重吉宛書簡―明治三十九年 > ../cards/000148/card2575.html\n",
      "西洋にはない > ../cards/000148/card42320.html\n",
      "戦争からきた行き違い > ../cards/000148/card2315.html\n",
      "創作家の態度 > ../cards/000148/card1102.html\n",
      "それから > ../cards/000148/card1746.html\n",
      "それから > ../cards/000148/card56143.html\n",
      "『それから』予告 > ../cards/000148/card4681.html\n",
      "高浜虚子著『鶏頭』序 > ../cards/000148/card2667.html\n",
      "田山花袋君に答う > ../cards/000148/card2370.html\n",
      "「土」に就て > ../cards/000148/card56900.html\n",
      "『土』に就て > ../cards/000148/card2668.html\n",
      "艇長の遺書と中佐の詩 > ../cards/000148/card4686.html\n",
      "手紙 > ../cards/000148/card798.html\n",
      "『伝説の時代』序 > ../cards/000148/card42156.html\n",
      "点頭録 > ../cards/000148/card4672.html\n",
      "『東洋美術図譜』 > ../cards/000148/card2313.html\n",
      "道楽と職業 > ../cards/000148/card757.html\n",
      "長塚節氏の小説「土」 > ../cards/000148/card2682.html\n",
      "中味と形式 > ../cards/000148/card788.html\n",
      "二百十日 > ../cards/000148/card751.html\n",
      "入社の辞 > ../cards/000148/card2673.html\n",
      "猫の広告文 > ../cards/000148/card4683.html\n",
      "野分 > ../cards/000148/card791.html\n",
      "『煤煙』の序 > ../cards/000148/card4684.html\n",
      "博士問題とマードック先生と余 > ../cards/000148/card787.html\n",
      "博士問題の成行 > ../cards/000148/card2376.html\n",
      "長谷川君と余 > ../cards/000148/card762.html\n",
      "彼岸過迄 > ../cards/000148/card765.html\n",
      "「額の男」を読む > ../cards/000148/card50478.html\n",
      "文芸委員は何をするか > ../cards/000148/card754.html\n",
      "文芸と道徳 > ../cards/000148/card756.html\n",
      "文芸とヒロイツク > ../cards/000148/card4685.html\n",
      "文芸の哲学的基礎 > ../cards/000148/card755.html\n",
      "文芸は男子一生の事業とするに足らざる乎 > ../cards/000148/card2681.html\n",
      "文士の生活 > ../cards/000148/card2679.html\n",
      "文壇の趨勢 > ../cards/000148/card2371.html\n",
      "文鳥 > ../cards/000148/card753.html\n",
      "変な音 > ../cards/000148/card763.html\n",
      "変な音 > ../cards/000148/card764.html\n",
      "僕の昔 > ../cards/000148/card1750.html\n",
      "坊っちゃん > ../cards/000148/card752.html\n",
      "マードック先生の『日本歴史』 > ../cards/000148/card2375.html\n",
      "正岡子規 > ../cards/000148/card1751.html\n",
      "幻影の盾 > ../cards/000148/card780.html\n",
      "満韓ところどころ > ../cards/000148/card781.html\n",
      "道草 > ../cards/000148/card783.html\n",
      "水底の感 > ../cards/000148/card58278.html\n",
      "無題 > ../cards/000148/card786.html\n",
      "明暗 > ../cards/000148/card782.html\n",
      "明治座の所感を虚子君に問れて > ../cards/000148/card2372.html\n",
      "模倣と独立 > ../cards/000148/card1747.html\n",
      "門 > ../cards/000148/card785.html\n",
      "門 > ../cards/000148/card56923.html\n",
      "夢十夜 > ../cards/000148/card799.html\n",
      "余と万年筆 > ../cards/000148/card2675.html\n",
      "予の描かんと欲する作品 > ../cards/000148/card2678.html\n",
      "落第 > ../cards/000148/card2676.html\n",
      "倫敦消息 > ../cards/000148/card779.html\n",
      "倫敦塔 > ../cards/000148/card1076.html\n",
      "吾輩は猫である > ../cards/000148/card789.html\n",
      "吾輩ハ猫デアル > ../cards/000148/card790.html\n",
      "『吾輩は猫である』下篇自序 > ../cards/000148/card2672.html\n",
      "『吾輩は猫である』上篇自序 > ../cards/000148/card47148.html\n",
      "『吾輩は猫である』中篇自序 > ../cards/000148/card2671.html\n",
      "私の経過した学生時代 > ../cards/000148/card2677.html\n",
      "私の個人主義 > ../cards/000148/card772.html\n"
     ]
    }
   ],
   "source": [
    "# body > ol:nth-child(8) > li:nth-child(1) > a\n",
    "# nth-chile(n)はn番目の子となる要素\n",
    "# この作品リストページを見ると、他に<ol>タグは使われていないため、省略しても良さそう\n",
    "# BearutifulSoupではnth-childの表記に対応していないため、代わりに、nth-of-typeを用いる\n",
    "\n",
    "url = \"http://www.aozora.gr.jp/index_pages/person148.html\"\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "li_list = soup.select(\"ol > li\")\n",
    "for li in li_list:\n",
    "    a = li.a\n",
    "    if a != None:\n",
    "        name = a.string\n",
    "        href = a.attrs[\"href\"]\n",
    "        print(name, \">\", href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSSセレクタをマスターしよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セレクタの基本書式\n",
    "\n",
    "|書式|説明|\n",
    "|:---|:---|\n",
    "|*|全ての要素|\n",
    "|要素名|要素名の要素 (例)p div|\n",
    "|.クラス名|クラス名をつけた要素|\n",
    "|#id名|id属性をつけた要素|\n",
    "\n",
    "セレクタ同士の関係を指定する書式\n",
    "\n",
    "|書式|説明|\n",
    "|:---|:---|\n",
    "|セレクタ,セレクタ|列挙された複数のセレクタ (例)h1, h2|\n",
    "|セレクタ セレクタ|下の階層の子孫要素 (例)div h1|\n",
    "|セレクタ>セレクタ|直下の階層の子要素 (例)div>h1|\n",
    "|セレクタ+セレクタ|同じ階層で直後に隣接している要素 (例)h1+h2|\n",
    "|セレクタ1~セレクタ2|セレクタ1からセレクタ2までの要素 (例)p~ul|\n",
    "\n",
    "セレクタの属性による指定書式\n",
    "\n",
    "|書式|説明|\n",
    "|:---|:---|\n",
    "|要素[att]|特定の属性名を持つ要素|\n",
    "|要素[att=\"val\"]|att属性にvalという値を持つ要素|\n",
    "|要素[att~=\"val\"]|att属性の値候補val(ホワイトスペース区切りに一致した要素)|\n",
    "|要素[att $|$ =\"val\"]|att属性の値がvalで始まる要素(ただしハイフン区切り)|\n",
    "|要素[att^=\"val\"]|att属性の値がvalで始まる要素|\n",
    "|要素[att$=\"val\"]|att属性の値がvalで終わる要素|\n",
    "|要素[att*=\"val\"]|att属性の値がvalを含む要素|\n",
    "\n",
    "位置や状態を指定する書式\n",
    "\n",
    "|書式|説明|\n",
    "|:---|:---|\n",
    "|要素 :root|ルートとなる要素|\n",
    "|要素 :nth-child(n)|n番目の子となる要素|\n",
    "|要素 :nth-last-child(n)|後ろからn番目となる要素|\n",
    "|要素 :nth-of-type(n)|n番目のその種類の要素|\n",
    "|要素 :first-child|子として最初の要素|\n",
    "|要素 :last-child|子として最後の要素|\n",
    "|要素 :first-of-type|最初のその種類の要素|\n",
    "|要素 :last-of-type|最後のその種類の要素|\n",
    "|要素 :only-child|子として唯一の要素|\n",
    "|要素 :only-of-type|子として唯一の種類の要素|\n",
    "|要素 :empty|要素内容が空となる要素|\n",
    "|要素 :lang(code)|特定の言語にcodeを指定された要素|\n",
    "|要素 :not(s)|s以外の要素|\n",
    "|要素 :enabled|有効となっているUI要素|\n",
    "|要素 :disabled|向こうとなっているUI要素|\n",
    "|要素 :checked|チェックされているUI要素|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSSセレクタを抽出する練習をしてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ul id=\"bible\">\n",
       "<li id=\"ge\">Genesis</li>\n",
       "<li id=\"ex\">Exodus</li>\n",
       "<li id=\"le\">Leviticus</li>\n",
       "<li id=\"nu\">Numbers</li>\n",
       "<li id=\"de\">Deuteronomy</li>\n",
       "</ul>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open(\"textFile/books.html\", encoding=\"utf-8\")\n",
    "soup = BeautifulSoup(fp, \"html.parser\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n"
     ]
    }
   ],
   "source": [
    "# CSSセレクタで検索する方法\n",
    "sel = lambda q : print(soup.select_one(q).string)\n",
    "sel(\"#nu\") # *1\n",
    "sel(\"li#nu\") # *2\n",
    "sel(\"ul > li#nu\") # *3\n",
    "sel(\"#bible #nu\") # *4\n",
    "sel(\"#bible > #nu\") # *5\n",
    "sel(\"ul#bible > li#nu\") # *6\n",
    "sel(\"li[id='nu']\") # *7\n",
    "sel(\"li:nth-of-type(4)\") # *8\n",
    "\n",
    "# その他の方法\n",
    "print(soup.select(\"li\")[3].string) # *9\n",
    "print(soup.find_all(\"li\")[3].string) # *10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1 オーソドックスに、id属性がnuのものを取り出している  \n",
    "*2 これに、$<li>$タグがついたもの  \n",
    "*3 一階層上の$<ul>$タグから指定している  \n",
    "*4 id属性を1つ書いて、$#bible$の下の$#nu$を指定している  \n",
    "*5 タグが直接の親子関係になっていることを明示している  \n",
    "*6 idがbibleである$<ul>$タグ、その直下にあるidがnuである$<li>$タグと明確な指示を与えている  \n",
    "*7 属性の検索を利用しており、idがnuである$<li>$タグという指定になる  \n",
    "*8 4つ目の$<li>$を取り出すという指定方法  \n",
    "*9 *10 select()やfind_all()メソッドを利用している いずれも全ての$<li>$タグを取得した上で、[3]の要素を取得する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSSセレクタで野菜・フルーツを選択しよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アボカドを抜き出したい\n",
    "fp = open(\"textFile/fruits-vegetables.html\", encoding=\"utf-8\")\n",
    "soup = BeautifulSoup(fp, \"html.parser\")\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "レモン\n",
      "アボカド\n",
      "アボカド\n",
      "アボカド\n",
      "アボカド\n",
      "アボカド\n"
     ]
    }
   ],
   "source": [
    "# CSSセレクタで選び出す\n",
    "print(soup.select_one(\"li:nth-of-type(3)\").string) # *1\n",
    "print(soup.select_one(\"#ve-list > li:nth-of-type(4)\").string) # *2\n",
    "print(soup.select(\"#ve-list > li[data-lo='us']\")[1].string) # *3\n",
    "print(soup.select(\"#ve-list > li.black\")[1].string) # *4\n",
    "    \n",
    "# findメソッド選び出す *5\n",
    "cond = {\"data-lo\":\"us\", \"class\":\"black\"}\n",
    "print(soup.find(\"li\", cond).string)\n",
    "\n",
    "# findメソッドを二度組み合わせる *6\n",
    "print(soup.find(id=\"ve-list\").find(\"li\", cond).string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1 全$<li>$タグの8個目の要素を取り出す(二つ目のulの際にエラーを吐く)  \n",
    "*2 野菜を表すidがve-listの直下にある$<li>$タグの4個目の要素を取り出す  \n",
    "*3 select()メソッドを使って、idがve-listの要素の直下にある$<li>$タグのうち、data-loぞくせいが　\"us\"の物を全部取り出して[1]を表示  \n",
    "*4 *3と同じ  \n",
    "*5 find()メソッドは複数の条件を一度に指定できるのが特徴  \n",
    "*6 find()メソッドを二重に組み合わせる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正規表現と組み合わせる方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # 正規表現を使う時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<ul>\n",
    "    <li><a href=\"hoge.html\">hoge</li>\n",
    "    <li><a href=\"https://example.com/fuga\">fuga*</li>\n",
    "    <li><a href=\"https://example.com/foo\">foo*</li>\n",
    "    <li><a href=\"http://example.com/aaa\">aaa</li>\n",
    "</ul>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://example.com/fuga\n",
      "https://example.com/foo\n"
     ]
    }
   ],
   "source": [
    "# 正規表現でhrefからhttpsのものを抽出\n",
    "li = soup.find_all(href=re.compile(r\"^https://\"))\n",
    "for e in li:\n",
    "    print(e.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リンク先を丸ごとダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相対パスを展開する方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/html/b.html\n",
      "http://example.com/html/sub/c.html\n",
      "http://example.com/index.html\n",
      "http://example.com/img/hoge.png\n",
      "http://example.com/css/hoge.css\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "base = \"http://example.com/html/a.html\"\n",
    "\n",
    "print(urljoin(base, \"b.html\"))\n",
    "print(urljoin(base, \"sub/c.html\"))\n",
    "print(urljoin(base, \"../index.html\"))\n",
    "print(urljoin(base, \"../img/hoge.png\"))\n",
    "print(urljoin(base, \"../css/hoge.css\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[書式] urllib.parse.urljoin()の使い方  \n",
    "urljoin(base, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もし解決したいパスがhttp://で始まっている場合には、基本的にURLを無視して、第二引数に指定したURLを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/hoge.html\n",
      "http://kujirahand.com/wiki\n",
      "http://uta.pw/shodou\n"
     ]
    }
   ],
   "source": [
    "print(urljoin(base, \"/hoge.html\"))\n",
    "print(urljoin(base, \"http://kujirahand.com/wiki\"))\n",
    "print(urljoin(base, \"//uta.pw/shodou\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再帰的にHTMLページを処理する\n",
    "\n",
    "htmlファイルにリンクが連鎖的に続いていた場合、その全てを解析する必要があり、それを処理するために再起処理を利用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 丸ごとダウンロードするプログラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールの取り込み\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import *\n",
    "from urllib.parse import *\n",
    "from os import makedirs\n",
    "import os.path, time, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 処理済み判断変数\n",
    "proc_files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML内にあるリンクを抽出する関数\n",
    "def enum_links(html, base):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = soup.select(\"link[rel='stylesheet']\") # CSS\n",
    "    links += soup.select(\"a[href]\") # リンク\n",
    "    result = []\n",
    "    # href属性を取り出し、リンクを絶対パスに変換\n",
    "    for a in links:\n",
    "        href = a.attrs['href']\n",
    "        url = urljoin(base, href)\n",
    "        result.append(url)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルをダウンロードし保存する関数\n",
    "def download_file(url):\n",
    "    o = urlparse(url)\n",
    "    savepath = \"./\" + o.netloc + o.path\n",
    "    if re.search(r\"/$\", savepath): # ディレクトリならindex.html\n",
    "        savepath += \"index.html\"\n",
    "    savedir = os.path.dirname(savepath)\n",
    "    # 既にダウンロード済み?\n",
    "    if os.path.exists(savepath):\n",
    "        return savepath\n",
    "    # ダウンロード先のディレクトリを作成\n",
    "    if not os.path.exists(savedir):\n",
    "        print(\"mkdir=\", savedir)\n",
    "        makedirs(savedir)\n",
    "    # ファイルをダウンロード\n",
    "    try:\n",
    "        print(\"download=\", url)\n",
    "        urlretrieve(url, savepath)\n",
    "        time.sleep(1) # 礼儀として1秒スリープ\n",
    "        return savepath\n",
    "    except:\n",
    "        print(\"ダウンロード失敗:\", url)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを解析してダウンロードする関数\n",
    "def analize_html(url, root_url):\n",
    "    savepath = download_file(url)\n",
    "    if savepath is None:\n",
    "        return\n",
    "    if savepath in proc_files: # 解析済みなら処理しない\n",
    "        return\n",
    "    proc_files[savepath] = True\n",
    "    print(\"analyze_html=\", url)\n",
    "    # リンクを抽出\n",
    "    html = open(savepath, \"r\", encoding=\"utf-8\").read()\n",
    "    links = enum_links(html, url)\n",
    "    for link_url in links:\n",
    "        # リンクがルート以外のパスを指していたら無視\n",
    "        if link_url.find(root_url) != 0:\n",
    "            if not re.search(r\".css$\", link_url):\n",
    "                continue\n",
    "        # HTMLか？\n",
    "        if re.search(r\".(html|htm)$\", link_url):\n",
    "            # 再帰的にHTMLファイルを解析\n",
    "            analize_html(link_url, root_url)\n",
    "            continue\n",
    "        # それ以外のファイル\n",
    "        download_file(link_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLを丸ごとダウンロード\n",
    "url = \"http://docs.python.jp/3.5/library/\"\n",
    "analize_html(url, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
